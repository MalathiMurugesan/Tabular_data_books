{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa65c0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428599b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6221a196",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85152d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "libraries are found\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import pandas as pd\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    print('libraries are found')\n",
    "except:\n",
    "    print('Some libraries need to be installed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3dc8905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read the data\n",
    "def read_data(path,file_name):\n",
    "    df = pd.read_hdf(path + filename)\n",
    "    return df\n",
    "filename = 'data_train_v7.h5'\n",
    "path = '/workspace/giacomo/bh_parts_forecasting/data/train/'\n",
    "data = read_data(path,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1b234ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to treat the missing values\n",
    "## remove columns which contain more than 50% of null values\n",
    "def treat_null_values(df):\n",
    "    \n",
    "    df = df.dropna(thresh=df.shape[0]*0.5, how='all',axis=1) # -3\n",
    "    df = df.dropna(axis=0,subset=['RECEIPT_DATE','BOOKED_DATE'])\n",
    "    \n",
    "    df = df[df['RECEIPT_DATE']>df['BOOKED_DATE']] # false\n",
    "       \n",
    "    return df\n",
    "\n",
    "df1 = treat_null_values(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe4fecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional function\n",
    "#  This funtion is to analyse the different types of columns # optional\n",
    "def analyze_data_types(df):\n",
    "    date_columns_df = df.select_dtypes(include=['datetime64'])\n",
    "    object_columns_df = df.select_dtypes(include=['object'])\n",
    "    numerics= [ 'int64','float64']\n",
    "    numeric_columns_df = df.select_dtypes(include = numerics)\n",
    "    \n",
    "    return date_columns_df, object_columns_df,numeric_columns_df\n",
    "\n",
    "date_df, objects_df,numeric_df=analyze_data_types(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a3819b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply feature engg here after this step\n",
    "# first apply on numeric_df columns\n",
    "# second on objects_df columns\n",
    "# third on date_df separately \n",
    "# for convenience "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89dcc47",
   "metadata": {},
   "source": [
    "## Feature Engineering - Numeric Columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fd37f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can remove UNIT_PRICE_USD as already AMOUNT_USD is there\n",
    "# we can remove 'ORG_ID',ATTRIBUTE_NUMBER1', 'ATTRIBUTE_NUMBER2',ATTRIBUTE_NUMBER6', 'ATTRIBUTE_NUMBER7', 'ATTRIBUTE_NUMBER8' as they have \n",
    "# only one unique value\n",
    "\n",
    "# see SO_LINE_FIRST and SO_LINE_LAST retain one col by finding the difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88e70b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_features(df,cols_to_drop):\n",
    "    df['diff_SO_LINE_FIRST_SO_LINE_LAST'] = df['SO_LINE_LAST'] - df['SO_LINE_FIRST']\n",
    "\n",
    "    df.drop(cols_to_drop,axis=1,inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "columns_to_remove = ['ORG_ID','ATTRIBUTE_NUMBER1','ATTRIBUTE_NUMBER2','ATTRIBUTE_NUMBER6','ATTRIBUTE_NUMBER7','ATTRIBUTE_NUMBER8',\n",
    "                    'UNIT_PRICE_USD','SO_LINE_FIRST','SO_LINE_LAST' ]\n",
    "df1 = drop_features(df1,columns_to_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbf95ad",
   "metadata": {},
   "source": [
    "## Feature Engineering - Objects Columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c3f77c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def treat_objects(df,col_to_drop):\n",
    "    \n",
    "    df.drop(col_to_drop,axis=1,inplace=True)\n",
    "    \n",
    "    object_columns_df = df.select_dtypes(include=['object'])\n",
    "    objects_col = list(object_columns_df.columns)\n",
    "    \n",
    "\n",
    "    # label encode the categorical variables\n",
    "    label_encoder = LabelEncoder()\n",
    "    for col in objects_col:\n",
    "         df[col] = label_encoder.fit_transform(df[col])\n",
    "            \n",
    "    return df\n",
    "cols_to_remove = ['PO_STRING','PROMISED_DATE']\n",
    "df1 = treat_objects(df1,cols_to_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f3340d",
   "metadata": {},
   "source": [
    "## Feature Engineering - Date Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df513266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to re-engineer the dates\n",
    "def difference_dates(df,col1,col2):\n",
    "            \n",
    "    df['diff_'+col1+col2]=(df[col1]-df[col2]).dt.days\n",
    "    df.drop([col1,col2],axis=1,inplace = True)\n",
    "    \n",
    "    return df\n",
    "# call function on the required features    \n",
    "df1 = difference_dates(df1,'RTS_','RTS_FINAL')\n",
    "df1 = difference_dates(df1,'SO_CWD','SO_CREATION_DATE')\n",
    "df1 = difference_dates(df1,'EOQ_CONTR','EOQ_REQUEST')\n",
    "df1 = difference_dates(df1,'CONTRACTUAL_DATE','FULFILLMENT_CONTRACTUAL_DATE')\n",
    "df1 = difference_dates(df1,'PO_FIRST_APPROVED_DATE','POR_APPROVED_DATE')\n",
    "df1 = difference_dates(df1,'RECEIPT_DATE','BOOKED_DATE') \n",
    "\n",
    "\n",
    "# since most of the rows are same as NEED_BY_DATE','NEED_DATE_FIRST', 'NEED_DATE_LAST'\n",
    "# 'NEED_BY_DATE' has same values as 'SUP_PO_NEED_BY_DATE'\n",
    "# instead of these 3 features only one feature can be used and name it 'NEED_DATE_'\n",
    "# 'DATE_WHEN_NEED_REV'\n",
    "df1['NEED_DATE_'] = df1['NEED_BY_DATE']\n",
    "df1.drop(['NEED_DATE_FIRST', 'NEED_DATE_LAST','SUP_PO_NEED_BY_DATE','DATE_WHEN_NEED_REV',\n",
    "         'NEED_BY_DATE','PROMISED_DATE_LAST'],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# both SCHEDULE_SHIP_DATE and 'LINE_REQUEST_DATE' are greater than NEED_DATE so take the diff\n",
    "df1['diff_SCHEDULE_SHIP_DATE_NEED_DATE_'] = (df1['SCHEDULE_SHIP_DATE']-df1['NEED_DATE_']).dt.days\n",
    "df1['diff_LINE_REQUEST_DATE_NEED_DATE_'] = (df1['LINE_REQUEST_DATE']-df1['NEED_DATE_']).dt.days\n",
    "df1.drop(['LINE_REQUEST_DATE','SCHEDULE_SHIP_DATE'],axis=1,inplace=True)\n",
    "#df1.drop('PROMISED_DATE',axis=1,inplace=True)  # this not datetime data type, and we drop this retaining PROMISED FIRST DATE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b5709c",
   "metadata": {},
   "source": [
    "## Save the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0aa512e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(df,file_name_train,file_name_test):\n",
    "    \n",
    "    data_cleaned = df.dropna()\n",
    "    data_cleaned =data_cleaned.reset_index(drop=True)\n",
    "    train_data,test_data = train_test_split(data_cleaned,test_size = 0.2)\n",
    "    train_data.to_csv(file_name_train,index=False)\n",
    "    test_data.to_csv(file_name_test,index=False)\n",
    "    \n",
    "    return True\n",
    "file1 = 'train_data_E2.csv'\n",
    "file2 = 'test_data_E2.csv'\n",
    "save_data(df1,file1,file2)\n",
    "save_data(df1,file1,file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97505e12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
