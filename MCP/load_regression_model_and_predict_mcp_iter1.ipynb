{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e267951",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe0eec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8fca8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "#tensorflow.random.set_seed(1)\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ecc429e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#http://10.79.85.55:8887/edit/data/MGP/TestPointsN2_CH4_H2O_000.xlsx\n",
    "file_name = '/data/MGP/TestPointsN2_CH4_H2O_000.xlsx'\n",
    "df=pd.read_excel(file_name,header=1).dropna(how='all', axis=1)\n",
    "df.drop('#',axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adcde6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['Pin [kPa]','Tin [K]','N [rpm]','Differential Pressure [kPa]','Total Consumed power','GVFin','Qin [m3/s]','GVFout','Qv_out [m3/s]']\n",
    "inputs = ['Pin [kPa]','Tin [K]','N [rpm]','Differential Pressure [kPa]','Total Consumed power']\n",
    "outputs = ['GVFin','Qin [m3/s]','GVFout','Qv_out [m3/s]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04d3c526",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfff5653",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictors = list(set(list(df.columns))-set(outputs))\n",
    "df[predictors] = df[predictors]/df[predictors].max()\n",
    "#df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26a5f63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[predictors].values\n",
    "y = df[outputs].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4ed4f5",
   "metadata": {},
   "source": [
    "## Train the model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a77c58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-30 13:11:15.631325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 237 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:8a:00.0, compute capability: 7.0\n",
      "2022-03-30 13:11:15.785038: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "632/632 [==============================] - 6s 5ms/step - loss: 11.7950 - mae: 11.7385 - val_loss: 8.6250 - val_mae: 8.5866\n",
      "Epoch 2/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 7.3221 - mae: 7.2855 - val_loss: 5.3601 - val_mae: 5.3245\n",
      "Epoch 3/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 5.2597 - mae: 5.2243 - val_loss: 4.1308 - val_mae: 4.0957\n",
      "Epoch 4/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 3.9470 - mae: 3.9118 - val_loss: 2.8735 - val_mae: 2.8382\n",
      "Epoch 5/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 3.0854 - mae: 3.0499 - val_loss: 2.4675 - val_mae: 2.4318\n",
      "Epoch 6/150\n",
      "632/632 [==============================] - 3s 5ms/step - loss: 2.5797 - mae: 2.5438 - val_loss: 1.8455 - val_mae: 1.8095\n",
      "Epoch 7/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 2.2427 - mae: 2.2066 - val_loss: 1.5069 - val_mae: 1.4707\n",
      "Epoch 8/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 2.0633 - mae: 2.0270 - val_loss: 1.4468 - val_mae: 1.4103\n",
      "Epoch 9/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.9931 - mae: 1.9566 - val_loss: 1.2155 - val_mae: 1.1790\n",
      "Epoch 10/150\n",
      "632/632 [==============================] - 3s 5ms/step - loss: 1.9267 - mae: 1.8901 - val_loss: 1.1757 - val_mae: 1.1390\n",
      "Epoch 11/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.8792 - mae: 1.8425 - val_loss: 1.0710 - val_mae: 1.0342\n",
      "Epoch 12/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.8682 - mae: 1.8314 - val_loss: 1.0616 - val_mae: 1.0248\n",
      "Epoch 13/150\n",
      "632/632 [==============================] - 3s 5ms/step - loss: 1.8299 - mae: 1.7930 - val_loss: 1.0398 - val_mae: 1.0029\n",
      "Epoch 14/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.8026 - mae: 1.7656 - val_loss: 1.0183 - val_mae: 0.9813\n",
      "Epoch 15/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.8132 - mae: 1.7762 - val_loss: 1.0293 - val_mae: 0.9922\n",
      "Epoch 16/150\n",
      "632/632 [==============================] - 3s 5ms/step - loss: 1.7897 - mae: 1.7526 - val_loss: 0.9881 - val_mae: 0.9510\n",
      "Epoch 17/150\n",
      "632/632 [==============================] - 3s 5ms/step - loss: 1.7866 - mae: 1.7495 - val_loss: 0.9845 - val_mae: 0.9473\n",
      "Epoch 18/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.7890 - mae: 1.7517 - val_loss: 1.0134 - val_mae: 0.9762\n",
      "Epoch 19/150\n",
      "632/632 [==============================] - 3s 5ms/step - loss: 1.7932 - mae: 1.7559 - val_loss: 0.9752 - val_mae: 0.9379\n",
      "Epoch 20/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.7723 - mae: 1.7350 - val_loss: 0.9872 - val_mae: 0.9499\n",
      "Epoch 21/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.7370 - mae: 1.6996 - val_loss: 0.9621 - val_mae: 0.9247\n",
      "Epoch 22/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.7757 - mae: 1.7384 - val_loss: 0.9806 - val_mae: 0.9432\n",
      "Epoch 23/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.7437 - mae: 1.7063 - val_loss: 0.9461 - val_mae: 0.9087\n",
      "Epoch 24/150\n",
      "632/632 [==============================] - 3s 5ms/step - loss: 1.7519 - mae: 1.7145 - val_loss: 0.9528 - val_mae: 0.9153\n",
      "Epoch 25/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.7803 - mae: 1.7428 - val_loss: 1.0597 - val_mae: 1.0222\n",
      "Epoch 26/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.7219 - mae: 1.6845 - val_loss: 0.9745 - val_mae: 0.9370\n",
      "Epoch 27/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.7392 - mae: 1.7017 - val_loss: 0.9364 - val_mae: 0.8989\n",
      "Epoch 28/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.7421 - mae: 1.7046 - val_loss: 0.9277 - val_mae: 0.8902\n",
      "Epoch 29/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.7658 - mae: 1.7283 - val_loss: 0.9488 - val_mae: 0.9112\n",
      "Epoch 30/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.7555 - mae: 1.7179 - val_loss: 0.9453 - val_mae: 0.9077\n",
      "Epoch 31/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.7445 - mae: 1.7069 - val_loss: 0.9235 - val_mae: 0.8859\n",
      "Epoch 32/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.7136 - mae: 1.6760 - val_loss: 0.9204 - val_mae: 0.8828\n",
      "Epoch 33/150\n",
      "632/632 [==============================] - 3s 5ms/step - loss: 1.7034 - mae: 1.6658 - val_loss: 0.9362 - val_mae: 0.8986\n",
      "Epoch 34/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6720 - mae: 1.6344 - val_loss: 0.9131 - val_mae: 0.8755\n",
      "Epoch 35/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.7126 - mae: 1.6750 - val_loss: 0.9116 - val_mae: 0.8740\n",
      "Epoch 36/150\n",
      "632/632 [==============================] - 3s 5ms/step - loss: 1.7211 - mae: 1.6834 - val_loss: 0.9139 - val_mae: 0.8762\n",
      "Epoch 37/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.7135 - mae: 1.6759 - val_loss: 0.9187 - val_mae: 0.8810\n",
      "Epoch 38/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.7151 - mae: 1.6774 - val_loss: 0.9149 - val_mae: 0.8772\n",
      "Epoch 39/150\n",
      "632/632 [==============================] - 3s 5ms/step - loss: 1.7426 - mae: 1.7049 - val_loss: 0.9017 - val_mae: 0.8640\n",
      "Epoch 40/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.7086 - mae: 1.6709 - val_loss: 0.9188 - val_mae: 0.8811\n",
      "Epoch 41/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.7101 - mae: 1.6723 - val_loss: 0.9092 - val_mae: 0.8714\n",
      "Epoch 42/150\n",
      "632/632 [==============================] - 3s 5ms/step - loss: 1.7179 - mae: 1.6801 - val_loss: 0.8989 - val_mae: 0.8611\n",
      "Epoch 43/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6990 - mae: 1.6612 - val_loss: 0.9260 - val_mae: 0.8882\n",
      "Epoch 44/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.7002 - mae: 1.6624 - val_loss: 0.9083 - val_mae: 0.8705\n",
      "Epoch 45/150\n",
      "632/632 [==============================] - 3s 5ms/step - loss: 1.6871 - mae: 1.6493 - val_loss: 0.9064 - val_mae: 0.8686\n",
      "Epoch 46/150\n",
      "632/632 [==============================] - 3s 5ms/step - loss: 1.7067 - mae: 1.6689 - val_loss: 0.8950 - val_mae: 0.8571\n",
      "Epoch 47/150\n",
      "632/632 [==============================] - 3s 5ms/step - loss: 1.7168 - mae: 1.6790 - val_loss: 0.9270 - val_mae: 0.8892\n",
      "Epoch 48/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6839 - mae: 1.6461 - val_loss: 0.8962 - val_mae: 0.8584\n",
      "Epoch 49/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6834 - mae: 1.6456 - val_loss: 0.8994 - val_mae: 0.8616\n",
      "Epoch 50/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6872 - mae: 1.6494 - val_loss: 0.8889 - val_mae: 0.8511\n",
      "Epoch 51/150\n",
      "632/632 [==============================] - 3s 5ms/step - loss: 1.6980 - mae: 1.6601 - val_loss: 0.8989 - val_mae: 0.8610\n",
      "Epoch 52/150\n",
      "632/632 [==============================] - 3s 5ms/step - loss: 1.7124 - mae: 1.6745 - val_loss: 0.8861 - val_mae: 0.8482\n",
      "Epoch 53/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6933 - mae: 1.6554 - val_loss: 0.8949 - val_mae: 0.8570\n",
      "Epoch 54/150\n",
      "632/632 [==============================] - 3s 5ms/step - loss: 1.7145 - mae: 1.6766 - val_loss: 0.8836 - val_mae: 0.8457\n",
      "Epoch 55/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6834 - mae: 1.6454 - val_loss: 0.8981 - val_mae: 0.8602\n",
      "Epoch 56/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6731 - mae: 1.6352 - val_loss: 0.8720 - val_mae: 0.8341\n",
      "Epoch 57/150\n",
      "632/632 [==============================] - 3s 5ms/step - loss: 1.7057 - mae: 1.6678 - val_loss: 0.8950 - val_mae: 0.8571\n",
      "Epoch 58/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6800 - mae: 1.6421 - val_loss: 0.9003 - val_mae: 0.8623\n",
      "Epoch 59/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6823 - mae: 1.6444 - val_loss: 0.8795 - val_mae: 0.8416\n",
      "Epoch 60/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6608 - mae: 1.6229 - val_loss: 0.8657 - val_mae: 0.8277\n",
      "Epoch 61/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.7007 - mae: 1.6627 - val_loss: 0.8959 - val_mae: 0.8579\n",
      "Epoch 62/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 3s 5ms/step - loss: 1.6929 - mae: 1.6549 - val_loss: 0.8944 - val_mae: 0.8564\n",
      "Epoch 63/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6621 - mae: 1.6242 - val_loss: 0.8700 - val_mae: 0.8320\n",
      "Epoch 64/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6980 - mae: 1.6600 - val_loss: 0.8753 - val_mae: 0.8373\n",
      "Epoch 65/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6848 - mae: 1.6468 - val_loss: 0.8667 - val_mae: 0.8287\n",
      "Epoch 66/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6712 - mae: 1.6332 - val_loss: 0.8677 - val_mae: 0.8297\n",
      "Epoch 67/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6833 - mae: 1.6453 - val_loss: 0.8664 - val_mae: 0.8284\n",
      "Epoch 68/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6701 - mae: 1.6320 - val_loss: 0.8686 - val_mae: 0.8306\n",
      "Epoch 69/150\n",
      "632/632 [==============================] - 3s 5ms/step - loss: 1.6763 - mae: 1.6383 - val_loss: 0.8662 - val_mae: 0.8282\n",
      "Epoch 70/150\n",
      "632/632 [==============================] - 4s 6ms/step - loss: 1.6811 - mae: 1.6431 - val_loss: 0.8587 - val_mae: 0.8206\n",
      "Epoch 71/150\n",
      "632/632 [==============================] - 3s 6ms/step - loss: 1.6819 - mae: 1.6439 - val_loss: 0.8614 - val_mae: 0.8234\n",
      "Epoch 72/150\n",
      "632/632 [==============================] - 3s 5ms/step - loss: 1.6367 - mae: 1.5986 - val_loss: 0.8702 - val_mae: 0.8322\n",
      "Epoch 73/150\n",
      "632/632 [==============================] - 3s 5ms/step - loss: 1.6454 - mae: 1.6073 - val_loss: 0.8591 - val_mae: 0.8210\n",
      "Epoch 74/150\n",
      "632/632 [==============================] - 3s 5ms/step - loss: 1.6545 - mae: 1.6165 - val_loss: 0.8611 - val_mae: 0.8231\n",
      "Epoch 75/150\n",
      "632/632 [==============================] - 3s 5ms/step - loss: 1.6427 - mae: 1.6046 - val_loss: 0.8599 - val_mae: 0.8219\n",
      "Epoch 76/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6680 - mae: 1.6300 - val_loss: 0.8681 - val_mae: 0.8301\n",
      "Epoch 77/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6687 - mae: 1.6306 - val_loss: 0.8698 - val_mae: 0.8317\n",
      "Epoch 78/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6849 - mae: 1.6469 - val_loss: 0.8986 - val_mae: 0.8605\n",
      "Epoch 79/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6561 - mae: 1.6180 - val_loss: 0.8621 - val_mae: 0.8240\n",
      "Epoch 80/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6580 - mae: 1.6200 - val_loss: 0.8536 - val_mae: 0.8155\n",
      "Epoch 81/150\n",
      "632/632 [==============================] - 3s 5ms/step - loss: 1.6476 - mae: 1.6095 - val_loss: 0.8597 - val_mae: 0.8216\n",
      "Epoch 82/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.7030 - mae: 1.6649 - val_loss: 0.8558 - val_mae: 0.8177\n",
      "Epoch 83/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6643 - mae: 1.6262 - val_loss: 0.8554 - val_mae: 0.8173\n",
      "Epoch 84/150\n",
      "632/632 [==============================] - 3s 5ms/step - loss: 1.6569 - mae: 1.6188 - val_loss: 0.8484 - val_mae: 0.8103\n",
      "Epoch 85/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6542 - mae: 1.6161 - val_loss: 0.8603 - val_mae: 0.8222\n",
      "Epoch 86/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6793 - mae: 1.6412 - val_loss: 0.8456 - val_mae: 0.8074\n",
      "Epoch 87/150\n",
      "632/632 [==============================] - 3s 5ms/step - loss: 1.6603 - mae: 1.6222 - val_loss: 0.8646 - val_mae: 0.8265\n",
      "Epoch 88/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6473 - mae: 1.6092 - val_loss: 0.8491 - val_mae: 0.8110\n",
      "Epoch 89/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6846 - mae: 1.6464 - val_loss: 0.8584 - val_mae: 0.8202\n",
      "Epoch 90/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6652 - mae: 1.6271 - val_loss: 0.8650 - val_mae: 0.8269\n",
      "Epoch 91/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6514 - mae: 1.6133 - val_loss: 0.8999 - val_mae: 0.8618\n",
      "Epoch 92/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6945 - mae: 1.6563 - val_loss: 0.8492 - val_mae: 0.8111\n",
      "Epoch 93/150\n",
      "632/632 [==============================] - 3s 5ms/step - loss: 1.6830 - mae: 1.6449 - val_loss: 0.8665 - val_mae: 0.8283\n",
      "Epoch 94/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6615 - mae: 1.6234 - val_loss: 0.8464 - val_mae: 0.8082\n",
      "Epoch 95/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6863 - mae: 1.6481 - val_loss: 0.8501 - val_mae: 0.8119\n",
      "Epoch 96/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6661 - mae: 1.6279 - val_loss: 0.8467 - val_mae: 0.8086\n",
      "Epoch 97/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6321 - mae: 1.5940 - val_loss: 0.8750 - val_mae: 0.8369\n",
      "Epoch 98/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6594 - mae: 1.6212 - val_loss: 0.8937 - val_mae: 0.8555\n",
      "Epoch 99/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6564 - mae: 1.6182 - val_loss: 0.8449 - val_mae: 0.8067\n",
      "Epoch 100/150\n",
      "632/632 [==============================] - 3s 5ms/step - loss: 1.6328 - mae: 1.5946 - val_loss: 0.8418 - val_mae: 0.8036\n",
      "Epoch 101/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6513 - mae: 1.6131 - val_loss: 0.8430 - val_mae: 0.8048\n",
      "Epoch 102/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6278 - mae: 1.5896 - val_loss: 0.8500 - val_mae: 0.8118\n",
      "Epoch 103/150\n",
      "632/632 [==============================] - 3s 5ms/step - loss: 1.6708 - mae: 1.6326 - val_loss: 0.8395 - val_mae: 0.8013\n",
      "Epoch 104/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6619 - mae: 1.6237 - val_loss: 0.8527 - val_mae: 0.8145\n",
      "Epoch 105/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6607 - mae: 1.6225 - val_loss: 0.8450 - val_mae: 0.8067\n",
      "Epoch 106/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6312 - mae: 1.5930 - val_loss: 0.8465 - val_mae: 0.8083\n",
      "Epoch 107/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6730 - mae: 1.6348 - val_loss: 0.8514 - val_mae: 0.8132\n",
      "Epoch 108/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6353 - mae: 1.5971 - val_loss: 0.8604 - val_mae: 0.8222\n",
      "Epoch 109/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6601 - mae: 1.6218 - val_loss: 0.8604 - val_mae: 0.8222\n",
      "Epoch 110/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6313 - mae: 1.5930 - val_loss: 0.8377 - val_mae: 0.7995\n",
      "Epoch 111/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6284 - mae: 1.5902 - val_loss: 0.8344 - val_mae: 0.7962\n",
      "Epoch 112/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6527 - mae: 1.6145 - val_loss: 0.8334 - val_mae: 0.7952\n",
      "Epoch 113/150\n",
      "632/632 [==============================] - 3s 5ms/step - loss: 1.6513 - mae: 1.6131 - val_loss: 0.8374 - val_mae: 0.7992\n",
      "Epoch 114/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6610 - mae: 1.6228 - val_loss: 0.8622 - val_mae: 0.8239\n",
      "Epoch 115/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6645 - mae: 1.6263 - val_loss: 0.8400 - val_mae: 0.8018\n",
      "Epoch 116/150\n",
      "632/632 [==============================] - 3s 5ms/step - loss: 1.6606 - mae: 1.6223 - val_loss: 0.8342 - val_mae: 0.7959\n",
      "Epoch 117/150\n",
      "632/632 [==============================] - 3s 5ms/step - loss: 1.6701 - mae: 1.6318 - val_loss: 0.8293 - val_mae: 0.7910\n",
      "Epoch 118/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6482 - mae: 1.6099 - val_loss: 0.8312 - val_mae: 0.7929\n",
      "Epoch 119/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6426 - mae: 1.6043 - val_loss: 0.8551 - val_mae: 0.8169\n",
      "Epoch 120/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6475 - mae: 1.6093 - val_loss: 0.8290 - val_mae: 0.7908\n",
      "Epoch 121/150\n",
      "632/632 [==============================] - 3s 5ms/step - loss: 1.6267 - mae: 1.5885 - val_loss: 0.8394 - val_mae: 0.8012\n",
      "Epoch 122/150\n",
      "632/632 [==============================] - 3s 5ms/step - loss: 1.6370 - mae: 1.5987 - val_loss: 0.8429 - val_mae: 0.8047\n",
      "Epoch 123/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6585 - mae: 1.6202 - val_loss: 0.8356 - val_mae: 0.7973\n",
      "Epoch 124/150\n",
      "632/632 [==============================] - 3s 5ms/step - loss: 1.6487 - mae: 1.6105 - val_loss: 0.8296 - val_mae: 0.7913\n",
      "Epoch 125/150\n",
      "632/632 [==============================] - 3s 5ms/step - loss: 1.6235 - mae: 1.5852 - val_loss: 0.8342 - val_mae: 0.7959\n",
      "Epoch 126/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6580 - mae: 1.6197 - val_loss: 0.8429 - val_mae: 0.8046\n",
      "Epoch 127/150\n",
      "632/632 [==============================] - 3s 5ms/step - loss: 1.7105 - mae: 1.6722 - val_loss: 0.8345 - val_mae: 0.7962\n",
      "Epoch 128/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6236 - mae: 1.5853 - val_loss: 0.8267 - val_mae: 0.7884\n",
      "Epoch 129/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6545 - mae: 1.6162 - val_loss: 0.8262 - val_mae: 0.7879\n",
      "Epoch 130/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6575 - mae: 1.6192 - val_loss: 0.8298 - val_mae: 0.7915\n",
      "Epoch 131/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6148 - mae: 1.5765 - val_loss: 0.8523 - val_mae: 0.8140\n",
      "Epoch 132/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6433 - mae: 1.6050 - val_loss: 0.8348 - val_mae: 0.7965\n",
      "Epoch 133/150\n",
      "632/632 [==============================] - 3s 5ms/step - loss: 1.6890 - mae: 1.6507 - val_loss: 0.8319 - val_mae: 0.7936\n",
      "Epoch 134/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6313 - mae: 1.5929 - val_loss: 0.8269 - val_mae: 0.7886\n",
      "Epoch 135/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6520 - mae: 1.6137 - val_loss: 0.8424 - val_mae: 0.8041\n",
      "Epoch 136/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6298 - mae: 1.5915 - val_loss: 0.8224 - val_mae: 0.7841\n",
      "Epoch 137/150\n",
      "632/632 [==============================] - 3s 5ms/step - loss: 1.6740 - mae: 1.6357 - val_loss: 0.8469 - val_mae: 0.8086\n",
      "Epoch 138/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6401 - mae: 1.6018 - val_loss: 0.8536 - val_mae: 0.8152\n",
      "Epoch 139/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6367 - mae: 1.5983 - val_loss: 0.8279 - val_mae: 0.7896\n",
      "Epoch 140/150\n",
      "632/632 [==============================] - 3s 5ms/step - loss: 1.6415 - mae: 1.6031 - val_loss: 0.8428 - val_mae: 0.8045\n",
      "Epoch 141/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6165 - mae: 1.5782 - val_loss: 0.8364 - val_mae: 0.7981\n",
      "Epoch 142/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6307 - mae: 1.5923 - val_loss: 0.8252 - val_mae: 0.7869\n",
      "Epoch 143/150\n",
      "632/632 [==============================] - 3s 5ms/step - loss: 1.6504 - mae: 1.6121 - val_loss: 0.8223 - val_mae: 0.7840\n",
      "Epoch 144/150\n",
      "632/632 [==============================] - 3s 5ms/step - loss: 1.6507 - mae: 1.6124 - val_loss: 0.8376 - val_mae: 0.7993\n",
      "Epoch 145/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6251 - mae: 1.5867 - val_loss: 0.8198 - val_mae: 0.7814\n",
      "Epoch 146/150\n",
      "632/632 [==============================] - 3s 5ms/step - loss: 1.6012 - mae: 1.5628 - val_loss: 0.8306 - val_mae: 0.7922\n",
      "Epoch 147/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6187 - mae: 1.5803 - val_loss: 0.8202 - val_mae: 0.7819\n",
      "Epoch 148/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6441 - mae: 1.6057 - val_loss: 0.8259 - val_mae: 0.7875\n",
      "Epoch 149/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6209 - mae: 1.5825 - val_loss: 0.8406 - val_mae: 0.8023\n",
      "Epoch 150/150\n",
      "632/632 [==============================] - 3s 4ms/step - loss: 1.6270 - mae: 1.5887 - val_loss: 0.8165 - val_mae: 0.7782\n"
     ]
    }
   ],
   "source": [
    "#import keras\n",
    "\n",
    "\n",
    "from tensorflow import keras \n",
    "from keras import optimizers\n",
    "\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\"mcp.h5\", save_best_only=True)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='normal', kernel_regularizer=\"l2\", input_shape=[X_train.shape[1]]),\n",
    "    keras.layers.Dropout(0.05),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    \n",
    "    keras.layers.Dense(64, activation='relu', kernel_initializer='normal', kernel_regularizer=\"l2\"),\n",
    "    keras.layers.Dropout(0.05),\n",
    "    keras.layers.BatchNormalization(),\n",
    "  \n",
    "    keras.layers.Dense(4)\n",
    "])\n",
    "\n",
    "model.compile(loss='mae',\n",
    "              optimizer=keras.optimizers.RMSprop(learning_rate=1e-2, decay=0.1),\n",
    "              metrics=['mae'])\n",
    "              \n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=150,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061b9194",
   "metadata": {},
   "source": [
    "## load the saved model and predict for unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e730ff43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Test 1.5455256430537685\n"
     ]
    }
   ],
   "source": [
    "# the saved model is loaded to make predictions on the new data(X_test)\n",
    "model_loaded = tf.keras.models.load_model('mcp.h5')\n",
    "\n",
    "# predictions from the saved model\n",
    "pred_test_loaded = model_loaded.predict(X_test)\n",
    "\n",
    "#print(\"RMSE Test\",np.sqrt(mean_squared_error(y_test,pred_test_loaded))) # optional get the error from the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3482ffa6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
